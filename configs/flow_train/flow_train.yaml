defaults:
  - _self_ # First takes priority so any properties redefined here take precedence
  - model: hr_unet
  - flow: mean
  - paths: ibme # Simply override in cli call

dataset:
  path: ${paths.data_path}/CAMUS_Latents_${vae.resolution}
  max_frames: 32
  batch_size: 5
  cond_pad_mask: true  # Whether to append the padding mask to the conditioning input
  masking_distribution: uniform  # Distribution to use for random masking; 'uniform' or 'geometric'

vae:
  resolution: 16f8 #(keep)
  scaling_factors:
    4f4: 0.1080
    4f8: 0.2232
    16f8: 1.33

  scaling_factor: ${vae.scaling_factors.${vae.resolution}}

trainer:
  lr: 1e-4
  lr_scheduler: CosineAnnealing
  loss_mask: pad
  uncond_prob: 0.0
  kwargs:
    max_epochs: 1000
    precision: 16
    accelerator: auto
    val_check_interval: 0.1
    accumulate_grad_batches: 5
    #profiler: simple
    #overfit_batches: 0.1 #debug

#ema:
#  kwargs:
#    decay: 0.999
#    start_step: 100
#    every_n_steps: 10
#    use_buffers: true


sample_every_n_val_steps: 800
ckpt:
  metric:
    monitor: val_loss
    filename: '{epoch}-{step}-{${ckpt.metric.monitor}:.3f}'
    save_top_k: 1
    mode: min
  periodic:
    filename: '{epoch}-{step}' #quote marks needed
    monitor: epoch
    mode: max
    save_top_k: 2
    every_n_epochs: 10
    save_last: True

  
wandb:
  project: go-with-the-flow
  entity: engemmanuel
  group: ${flow.type}
  #mode: offline

hydra:
  run:
    dir: ${paths.train_output_path}/hydra_outputs/test_max_size/${now:%Y-%m-%d}/${now:%H-%M-%S}